trigger:
  branches:
    include:
      - feature*

pool:
  vmImage: ubuntu-latest
strategy:
  matrix:
    Python38:
      python.version: '3.8'

steps:
- task: UsePythonVersion@0
  inputs:
    versionSpec: '$(python.version)'
  displayName: 'Use Python $(python.version)'


- script: |
    python ci_cd_scripts/read_config_cli.py config.json
  displayName: 'Set env variables from JSON cfg file'

- task: AzureCLI@2
  inputs:
    azureSubscription: 'xx'
    scriptType: 'bash'
    scriptLocation: 'inlineScript'
    inlineScript: |
      az keyvault network-rule add --ip-address $(curl ipinfo.io/ip) --name $(keyvault_name)
    addSpnToEnvironment: true
  displayName: 'Add current IP to the keyvault whitelist'

- task: AzureKeyVault@2
  inputs:
    azureSubscription: 'xx'
    KeyVaultName: 'xxx'
    SecretsFilter: '*'
    RunAsPreJob: false
  displayName: 'Get secrets from the keyvault'

- task: AzureCLI@2
  inputs:
    azureSubscription: 'xx'
    scriptType: 'bash'
    scriptLocation: 'inlineScript'
    inlineScript: |
      az keyvault network-rule remove --ip-address $(curl ipinfo.io/ip)/32 --name $(keyvault_name)
    addSpnToEnvironment: true
    condition: always()
  displayName: 'Remove current IP from the whitelist'

- script: |
    python -m pip install --upgrade pip
    pip install wheel
  displayName: 'Upgrade pip and install wheel package'

- script: |
    python ci_cd_scripts/find_files_cli.py find_files_in_nested_dir_job $(Build.Repository.LocalPath) 1 requirements txt
  displayName: 'Find dependencies and output them as bash variable'

- script: |
    python ci_cd_scripts/process_requirements_locally_cli.py $(requirements_files) dev
  displayName: 'Install dependencies using cli script'

- script: |
    python ci_cd_scripts/find_files_cli.py find_files_in_nested_dir_job $(Build.Repository.LocalPath) 1 None py setup
  displayName: 'Find setup.py files'

- script: |
    python ci_cd_scripts/build_packages_cli.py $(setup_files)
  displayName: 'Build wheel files'

- script: |
    echo "y
    $(databricks_host)
    $(databricks_token)
    $(databricks_cluster_id)
    $(databricks_org_id)
    $(databricks_port)" | databricks-connect configure
  displayName: 'Configure DBConnect'

- script: |
    python -m pytest --junit-xml=$(Build.Repository.LocalPath)/TEST-LOCAL.xml || true
  displayName: 'Run Python Unit Tests using DBConnect'

- task: PublishTestResults@2
  inputs:
    testResultsFiles: '**/TEST-*.xml'
    failTaskOnFailedTests: true
    publishRunAttachments: true

- script: |
    git diff --name-only --diff-filter=AMR HEAD^1 HEAD | xargs -I '{}' cp --parents -r '{}' $(Build.BinariesDirectory)
    mkdir -p $(Build.BinariesDirectory)/libraries/python/libs
    mkdir -p $(Build.BinariesDirectory)/libraries/python/libs/ci_cd_scripts
    cp $(Build.Repository.LocalPath)/ci_cd_scripts/*.* $(Build.BinariesDirectory)/libraries/python/libs/ci_cd_scripts
    cp $(Build.Repository.LocalPath)/config.json $(Build.BinariesDirectory)/libraries/python/libs/
  displayName: 'Get Changes for Azure Pipeline Artifact, copy ci_cd_scripts and config to the artifact directory'

- script: |
    python ci_cd_scripts/find_files_cli.py find_files_in_nested_dir_job $(Build.Repository.LocalPath) 1 dist whl
  displayName: 'Find whl files using python script and export output as bash variable'

- script: |
    python $(Build.Repository.LocalPath)/ci_cd_scripts/copy_files_cli.py copy_files $(Build.BinariesDirectory)/libraries/python/libs $(dist_files)
  displayName: 'Copy wheel files to the artifact directory'

- script: |
    python $(Build.Repository.LocalPath)/ci_cd_scripts/discover_and_copy_notebooks_cli.py $(Build.Repository.LocalPath) notebooks $(Build.BinariesDirectory)/libraries/python/libs/ci_cd_scripts/notebooks
  displayName: 'Copy notebooks to the artifact directory'

- script: |
    python $(Build.Repository.LocalPath)/ci_cd_scripts/create_init_script_cli.py $(Build.BinariesDirectory)/libraries/python/libs $(Build.BinariesDirectory)/libraries/python/libs/databricks_init_script.sh $(dbfs_package_dir) $(whl_files) $(requirements_files)
  displayName: 'Create init script'

- script: |
    python $(Build.Repository.LocalPath)/ci_cd_scripts/copy_files_cli.py copy_requirements $(Build.BinariesDirectory)/libraries/python/libs $(requirements_files)
  displayName: 'Copy requirements files to the artifact directory'

- task: ArchiveFiles@2
  inputs:
    includeRootFolder: true
    archiveType: 'zip'
    archiveFile: '$(Build.ArtifactStagingDirectory)/$(Build.BuildId).zip'
    replaceExistingArchive: true
    rootFolderOrFile: '$(Build.BinariesDirectory)/libraries/python/libs'

- task: PublishBuildArtifacts@1
  inputs:
    ArtifactName: 'DatabricksBuild'

- task: UniversalPackages@0
  inputs:
    command: 'publish'
    publishDirectory: '$(Build.ArtifactStagingDirectory)'
    feedsToUsePublish: 'internal'
    vstsFeedPublish: 'xx/yy'
    vstsFeedPackagePublish: 'project1'
    versionOption: 'patch'
    packagePublishDescription: 'Publishing using universal packaging with versioning from devops'
  displayName: 'Publish package using universal packaging method'

